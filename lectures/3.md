{% include mathjax %}

<!-- MarkdownTOC -->

- [3. Методи розв'язання систем лінійних алгебраїчних рівнянь \(СЛАР\)](#3-методи-розвязання-систем-лінійних-алгебраїчних-рівнянь-слар)
	- [3.1. Метод Гаусса](#31-метод-гаусса)
	- [3.2. Метод квадратних коренів](#32-метод-квадратних-коренів)
	- [3.3. Обчислення визначника та оберненої матриці](#33-обчислення-визначника-та-оберненої-матриці)
	- [3.4. Метод прогонки](#34-метод-прогонки)

<!-- /MarkdownTOC -->

<a id="3-методи-розвязання-систем-лінійних-алгебраїчних-рівнянь-слар"></a>
## 3. Методи розв'язання систем лінійних алгебраїчних рівнянь (СЛАР)

Методи розв'язування СЛАР поділяються на прямі та ітераційні. При умові точного виконання обчислень прямі методи за скінчену кількість операцій в результаті дають точний розв'язок. Використовуються вони для невеликих та середніх СЛАР $$n = 10^2 - 10^4$$. Ітераційні методи використовуються для великих СЛАР $$n > 10^5$$, як правило розріджених. В результаті отримуємо послідовність наближень, яка збігається до розв'язку.

<a id="31-метод-гаусса"></a>
### 3.1. Метод Гаусса

Література:

- Самарский, Гулин, 49&ndash;67: [djvu](../books/samarskyi-gulin-1989.djvu), [pdf](../books/samarskyi-gulin-1989-49-67.pdf);

- Березин, Жидков, том II, 10&ndash;23: [djvu](../books/berezin-zhidkov-ii-1962.djvu), [pdf](../books/berezin-zhidkov-ii-1962-10-23.pdf).

Розглянемо задачу розв'язання СЛАР

\begin{equation}
	\label{eq:3.1.1}
	A \vec x = \vec b,	
\end{equation}

причому $$A = (a_{ij})_{i, j = 1}^n$$, $$\det A \ne 0$$, $$\vec x = (x_i)_{i = 1}^n$$, $$\vec b = (b_j)_{j = 1}^n$$. Метод Крамера з обчисленням визначників для такої системи має складність $$Q = O(n! \cdot n)$$.

Запишемо СЛАР у вигляді

$$
\left\{
	\begin{aligned}
		& a_{1, 1} x_1 + a_{1, 2} x_2 + \ldots + a_{1, n} x_n = b_1 \equiv a_{1, n + 1}, \\
		& a_{2, 1} x_1 + a_{2, 2} x_2 + \ldots + a_{2, n} x_n = b_2 \equiv a_{2, n + 1}, \\
		& \ldots \\
		& a_{n, 1} x_1 + a_{n, 2} x_2 + \ldots + a_{n, n} x_n = b_n \equiv a_{n, n + 1}.
	\end{aligned}
\right.
$$

Якщо $$a_{1, 1} \ne 0$$, то ділимо перше рівняння на нього і виключаємо $$x_1$$ з інших рівнянь:

$$
\left\{
	\begin{aligned}
		x_1 + a_{1, 2}^{(1)} x_2 + \ldots + a_{1, n}^{(1)} x_n = a_{1, n + 1}^{(1)}, & \newline
		a_{2, 2}^{(1)} x_2 + \ldots + a_{2, n}^{(1)} x_n = a_{2, n + 1}^{(1)}, & \newline
		\ldots & \newline
		a_{n, 2} x_2^{(1)} + \ldots + a_{n, n}^{(1)} x_n = a_{n, n + 1}^{(1)} &.
	\end{aligned}
\right.
$$

Процес повторюємо для $$x_2, \ldots, x_n$$. В результаті отримуємо систему з трикутною матрицею

$$
\left\{ 
	\begin{array}{r}
		x_1 + a_{1, 2}^{(1)} x_2 + \ldots + a_{1, n}^{(1)} x_n = a_{1, n + 1}^{(1)},  \newline
		x_2 + \ldots + a_{2, n}^{(2)} x_n = a_{2, n + 1}^{(2)}, \newline
		\ldots \newline
		x_n = a_{n, n + 1}^{(n)}.
	\end{array}
\right.
$$

Тобто
\begin{equation}
	\label{eq:3.1.2}
	A^{(n)} \vec x = \vec a^{(n)}.
\end{equation}

Це прямий хід методу Гаусса. Формули прямого ходу

```python
for k in range(1, n):
  for j in range(k + 1, n + 2):
    a[k, j][k] = a[k, j][k - 1] / a[k, k][k - 1]
    for i in range(k + 1, n + 1):
      a[i, j][k] = a[i, j][k - 1] - \
        a[i, j][k - 1] * a[k, j][k]
```

Звідси

\begin{equation}
	\label{eq:3.1.3}
	x_n = a_{n, n + 1}^{(n)}, \quad x_i = a_{i, n + 1}^{(i)} - \Sum_{j = i + 1}^n a_{i, j}^{(n)} x_j,
\end{equation}

для $$i = \overline{n - 1, 1}$$. Це формули оберненого ходу.

Складність, тобто кількість операцій, яку необхідно виконати для реалізації методу: $$Q_{\text{пр.}} = 2/3 n^2 + O(n^2)$$ для прямого ходу, $$Q_{\text{об.}} = n^2 + O(n)$$ для оберненого ходу.

Умова $$a_{k, k}^{(k - 1)} \ne 0$$ не суттєва, оскільки знайдеться $$m$$, для якого $$\vert a_{m, k}^{(k - 1)} \vert = \Max_i \vert a_{i, k}^{(k - 1)} \vert \ne 0$$ (оскільки $$\det A \ne 0$$). Тоді міняємо місцями рядки номерів $$k$$ і $$m$$. Елемент $$a_{k, k}^{(k - 1)} \ne 0$$ називається ведучим.

Введемо матриці

$$
M_k = \begin{pmatrix} 
	1 & \cdots & 0 & \cdots & 0 \\ 
	\vdots & \ddots & \vdots & \ddots & \vdots \\ 
	0 & \cdots & m_{k,k} & \cdots & 0 \\ 
	\vdots & \ddots & \vdots & \ddots & \vdots \\ 
	0 & \cdots & m_{n,k} & \cdots & 1
\end{pmatrix}
$$

елементи якої обчислюється так: $$m_{k, k} = \frac{1}{a_{k, k}^{(k - 1)}}$$, $$m_{k, k} = - \frac{a_{i, k}^{(k - 1)}}{a_{k, k}^{(k - 1)}}$$.

Нехай на $$k$$-му кроці $$A_{k - 1} \vec x = \vec b_{k - 1}$$. Множимо цю СЛАР зліва на $$M_k$$: $$M_k A_{k - 1} \vec x = M_K \vec b_{k - 1}$$. Позначимо $$A_k = M_k A_{k - 1}$$; $$A_0 = A$$. Тоді прямий хід методу Гаусса можна записати у вигляді

$$
M_n M_{n - 1} \ldots M_1 A \vec x = M_n M_{n - 1} \ldots M_1 \vec b.
$$

Позначимо останню систему, яка співпадає з \eqref{eq:3.1.2}, так

\begin{equation}
	\label{eq:3.1.4}
	U \vec x = \vec c, \quad U = (u_{i, j})_{i, j = 1}^n,
\end{equation}

причому

$$
\begin{cases}
	u_{i, i} = 1, & \\
	u_{i, j} = 0, & i > j.
\end{cases}
$$

Таким чином $$U = M_n M_{n - 1} \ldots M_1 A$$. Введемо матриці

$$
L_k = M_k^{-1} = \begin{pmatrix} 
	1 & \cdots & 0 & \cdots & 0 \\ 
	\vdots & \ddots & \vdots & \ddots & \vdots \\ 
	0 & \cdots & a_{k,k}^{(k-1)} & \cdots & 0 \\ 
	\vdots & \ddots & \vdots & \ddots & \vdots \\ 
	0 & \cdots & a_{n,k}^{(k-1)} & \cdots & 1 
\end{pmatrix}
$$

Тоді

$$
A = L_1 \ldots L_n U = L U; \quad L = L_1 \ldots L_n,
$$

де $$L$$ &mdash; нижня трикутня матриця, $$U$$ &mdash; верхня трикутня матриця. Таким чином метод Гаусса можна трактувати, як розклад матриці $$A$$ в добуток двох трикутних матриць &mdash; $$LU$$-розклад.

Введемо матрицю перестановок на $$k$$-му кроці (це матриця, отримана з одиничної матриці перестановкою $$k$$-того і $$m$$-того рядка). Тоді при множені на неї матриці $$A_{k - 1}$$ робимо ведучим елементом максимальний за модулем.

$$
P_k = \begin{pmatrix} 
	1 & \cdots & 0 & \cdots & 0 & \cdots & 0 \\ 
	\vdots & \ddots & \vdots & \ddots & \vdots & \ddots & \vdots \\ 
	0 & \cdots & 0 & \cdots & 1 & \cdots & 0 \\ 
	\vdots & \ddots & \vdots & \ddots & \vdots & \ddots & \vdots \\ 
	0 & \cdots & 1 & \cdots & 0 & \cdots & 0 \\ 
	\vdots & \ddots & \vdots & \ddots & \vdots & \ddots & \vdots \\ 
	0 & \cdots & 0 & \cdots & 0 & \cdots & 1 \\ 
\end{pmatrix}
$$

За допомогою цих матриць перехід до трикутної системи \eqref{eq:3.1.4} тепер має вигляд:

$$
M_n M_{n - 1} P_{n - 1} \ldots M_1 P_1 A \vec x = M_n M_{n - 1} P_{n - 1} \ldots M_1 P_1 \vec b.
$$

**Твердження:** Знайдеться така матриця $$P$$ перестановок, що $$P A = L U$$ &mdash; розклад матриці на нижню трикутну з ненульовими діагональними елементами і верхню трикутну матрицю з одиницями на діагоналі.

Висновки про **переваги** трикутного розкладу:

- Розділення прямого і оберненого ходів дає змогу економно розв'язувати декілька систем з одноковою матрицею та різними правими частинами.

- Зберігання $$M$$, або $$L$$ та $$U$$ на місці $$А$$.

- Обчислюючи $$\ell$$ &mdash; кількість перестановок, можна встановити знак визначника.

<a id="32-метод-квадратних-коренів"></a>
### 3.2. Метод квадратних коренів

Література:

- Самарский, Гулин, 69&ndash;73: [djvu](../books/samarskyi-gulin-1989.djvu), [pdf](../books/samarskyi-gulin-1989-69-73.pdf);

- Березин, Жидков, том II, 23&ndash;25: [djvu](../books/berezin-zhidkov-ii-1962.djvu), [pdf](../books/berezin-zhidkov-ii-1962-23-25.pdf).

Цей метод призначений для розв'язання систем рівнянь із симетричною матрицею

\begin{equation}
	\label{eq:3.2.1}
	A \vec x = \vec b, \quad A^\intercal = A.
\end{equation}

Він оснований на розкладі матриці $$A$$ в добуток:

\begin{equation}
	\label{eq:3.2.2}
	A = S^\intercal D S,
\end{equation}

де $$S$$ &mdash; верхня трикутна матриця, $$S^\intercal$$ &mdash; нижня трикутна матриця, $$D$$ &mdash; діагональна матриця.

Виникає питання: як обчислити $$S$$, $$D$$ по матриці $$A$$? Маємо

$$
\begin{equation}
	\label{eq:3.2.3}
	DS_{i, j} = \begin{cases}
		d_{i, i} s_{i, j}, & i \le j, \\
		0, & i > j.
	\end{cases}
\end{equation}
$$

$$
\begin{align}
	S^\intercal DS_{i, j} &= \Sum_{l = 1}^n s_{i, l}^\intercal d_{l, l} s_{l, j} = \nonumber \newline
	&= \Sum_{l = 1}^{i - 1} s_{l, i}^\intercal s_{l, j} d_{l, l} + s_{i, i} s_{i, j} d_{i, i} + \nonumber \newline
	&\quad + \underset{= 0}{\underbrace{s_{l, i}^\intercal \Sum_{l = i + 1}^n s_{l, i}^\intercal s_{l, j} d_{l, l}}} = a_{i, j}, 
\end{align}
$$

для $$i, j = \overline{1, n}$$.

Якщо $$i = j$$, то

$$
\vert s_{i, i}^2 \vert d_{i, i} = a_{i, i} - \Sum_{l = 1}^{i - 1} \vert s_{l, i}^2 \vert d_{l, l} \equiv p_i.
$$

Тому

$$
d_{i,i} = \text{sign}(p_i), \quad s_{i,i} = \sqrt{\vert p_i \vert}.
$$

Якщо $$i < j$$, то 

$$
s_{i,j} = \left( a_{i,j} - \Sum_{l = 1}^{i - 1} s_{l,i}^\intercal d_{l,l} s_{l,j} \right) / (s_{i,i} d_{i,i}),
$$

де $$i = \overline{1, n}$$, а $$j = \overline{i + 1, n}$$.

Якщо $$A > 0$$ (тобто головні мінори матриці $$A$$ додатні), то всі $$d_{i,i} = +1$$.

Знайдемо розв'язок рівняння \eqref{eq:3.2.1}. Враховуючи \eqref{eq:3.2.2}, маємо:

\begin{equation}
	\label{eq:3.2.4}
	S^T D \vec y = \vec b
\end{equation}

і

\begin{equation}
	\label{eq:3.2.5}
	S \vec x = \vec y
\end{equation}

Оскільки $$S$$ &mdash; верхня трикутна матриця, а $$S^\intercal D$$ &mdash; нижня трикутна матриця, то

\begin{equation}
	\label{eq:3.2.6}
	y_i = \frac{b_i - \Sum_{j = 1}^{i - 1} s_{j,i} d_{j,j} y_j}{s_{i,i} d_{i,i}},
\end{equation}

для $$i = \overline{1, n}$$ і

\begin{equation}
	\label{eq:3.2.7}
	x_i = \frac{y_i - \Sum_{j = 1}^{i - 1} s_{i, j} x_j}{s_{i,i}},
\end{equation}

для $$i = \overline{n - 1, 1}$$, де $$x_n = \frac{y_n}{s_{n,n}}$$.

Метод застосовується лише для симетричних матриць. Його складність $$Q = \frac{n^3}{3} + O(n^2)$$.

**Переваги** цього методу:

- він витрачає в 2 рази менше пам'яті ніж метод Гаусса для зберігання $$A^\intercal = A$$ (необхідний об'єм пам'яті $$\frac{n(n+1)}{2} \sim \frac{n^2}{2}$$;

- метод однорідний, без перестановок;
	
- якщо матриця $$A$$ має багато нульових елементів, то і матриця $$S$$ також.

Остання властивість дає економію в пам'яті та кількості арифметичних операцій. Наприклад, якщо $$A$$ має $$m$$ ненульових стрічок по діагоналі ($$m$$-діагональна), то $$Q = O(m^2 n)$$.

<a id="33-обчислення-визначника-та-оберненої-матриці"></a>
### 3.3. Обчислення визначника та оберненої матриці

Література:

- Самарский, Гулин, 67&ndash;69: [djvu](../books/samarskyi-gulin-1989.djvu), [pdf](../books/samarskyi-gulin-1989-67-69.pdf);

Кількість операцій обчислення детермінанту за означенням &mdash; $$Q_{\det} = n!$$. В методі Гаусса &mdash; $$P A = L U$$. Тому

$$
\det P \det A = \det L \det U
$$

звідки

$$
\det A = (-1)^\ell \det L \det U = (-1)^\ell \Prod_{k = 1}^n a_{k, k}^{(k)},
$$

де $$\ell$$ &mdash; кількість перестановок. Ясно, що за методом Гаусса

$$
Q_{\det} = \frac{2}{3} \cdot n^3 + O(n^2)
$$

В методі квадратного кореня $$A = S^\intercal DS$$. Тому

\begin{equation}
	\label{eq:3.4.2}
	\det A = \det S^\intercal \det D \det S = \Prod_{k = 1}^n d_{k, k} \Prod_{k = 1}^n s_{k, k}^2.
\end{equation}

Тепер $$Q_{\det} = \frac{n^3}{3} + O(n^2)$$.

За означенням

\begin{equation}
	\label{eq:3.4.3}
	A A^{-1} = E,
\end{equation}

де $$A^{-1}$$ обернена до матриці $$A$$. Позначимо

$$
A^{-1} = (\alpha_{i, j})_{i, j = 1}^n.
$$

Тоді $$\vec \alpha_j = (\alpha_{i, j})_{i = 1}^n$$ &mdash; вектор-стовпчик оберненої матриці. З \eqref{eq:3.4.3} маємо

\begin{equation}
	\label{eq:3.4.5}
	A \vec \alpha_j = \vec e_j, \quad j = \overline{1, n}.
\end{equation}

де $$\vec e_j$$ &mdash; стовпчики одиничної матриці: $$\vec e_j = (\delta_{i, j})_{i = 1}^n$$,

$$
\delta_{i, j} = \begin{cases}
	1, & i = j, \\
	0, & i \ne j.
\end{cases}
$$

Для знаходження $$А^{-1}$$ необхідно розв'язати $$n$$ систем. Для знаходження $$А^{-1}$$ методом Гаусса необхідна кількість операцій $$Q = 2 n^3 + O(n^2)$$.

<a id="34-метод-прогонки"></a>
### 3.4. Метод прогонки

Література:

- Самарский, Гулин, 45&ndash;47: [djvu](../books/samarskyi-gulin-1989.djvu), [pdf](../books/samarskyi-gulin-1989-45-47.pdf);

Це економний метод для розв'язання СЛАР з три діагональною матрицею:

\begin{align}
	- c_0 y_0 + b_0 y_1 = - f_0, \label{eq:3.4.1} \newline
	a_i y_{i - 1} - c_i y_i + b_i y_{i + 1} = - f_i, \label{eq:3.4.2} \newline
	a_N y_{N - 1} - c_N y_N = - f_N. \label{eq:3.4.3}
\end{align}

Матриця системи

$$
A = \begin{pmatrix} 
	-c_0 & b_1 & & 0 \\ 
	a_0 & -c_1 & \ddots & \\ 
	& \ddots & \ddots & b_N \\ 
	0 & & a_N & -c_N
\end{pmatrix}
$$

тридіагональна.

Розв'язок представимо у вигляді

\begin{equation}
	\label{eq:3.4.4}
	y_i = \alpha_{i + 1} y_{i + 1} + \beta_{i + 1}, \quad i = \overline{0, N - 1}.
\end{equation}

Замінимо в \eqref{eq:3.4.4} i $$i \mapsto i - 1$$ і підставимо в \eqref{eq:3.4.2}, тоді

$$
(a_i \alpha_i - c_i) \cdot y_i + b_i y_{i + 1} = - f_i - a_i \beta_i
$$

Звідси

$$
y_i = \frac{b_i}{c_i - a_i \alpha_i} \cdot y_{i + 1} + \frac{f_i + a_i \beta_i}{c_i - a_i \alpha_i}.
$$

Тому з \eqref{eq:3.4.5} 

$$
\alpha_{i + 1} = \frac{b_i}{c_i - a_i \alpha_i}, \quad \beta_{i + 1} = \frac{f_i + a_i \beta_i}{c_i - a_i \alpha_i}, \quad i = \overline{1, N - 1}.
$$

Умова розв'язності \eqref{eq:3.4.1} &mdash; $$c_i - a_i \alpha_i \ne 0$$.

Щоб знайти всі $$\alpha_i$$, $$\beta_i$$, треба задати перші значення. З \eqref{eq:3.4.1}:

$$
\alpha_1 = \frac{b_0}{c_0}, \quad \beta_1 = \frac{f_0}{c_0}.
$$

Після знаходження всіх $$\alpha_i$$, $$\beta_i$$ обчислюємо $$y_N$$ з системи

$$
\left\{
	\begin{array}{l}
		a_N y_N - c_N y_N = - f_N, \\
		y_{N - 1} = \alpha_N y_N + \beta_N.
	\end{array}
\right.
$$

Звідси

\begin{equation}
	y_N = \frac{f_N + a_N \beta_N}{c_N - a_N \alpha_N}.
\end{equation}

**Алгоритм:**

```python
alpha[1], beta[1] = b[0] / c[0], f[0] / c[0]

for i in range(1, N):
  z[i] = c[i] - a[i] * alpha[i]
  alpha[i + 1], beta[i + 1] = b[i] / z[i], \
    (f[i] + a[i] * beta[i]) / z[i]

y[N] = (f[N] + a[N] * beta[N]) / \
  (c[N] - a[N] * alpha[N])

for i in range(N - 1, -1, -1):
  y[i] = alpha[i + 1] * y[i + 1] + beta[i + 1]
```

Складність алгоритму $$Q = 8 N - 2$$.

Метод можна застосовувати, коли $$c_i - a_i \alpha_i \ne 0$$, $$\forall i: \vert \alpha_i \vert \le 1$$. Якщо $$\vert \alpha_i \vert \ge q > 1$$ то $$\Delta y_0 \ge q^N \Delta y_N$$ (тут $$\Delta y_i$$ абсолютна похибка обчислення $$y_i$$), а це приводить до експоненціального накопичення похибок заокруглення, тобто нестійкості алгоритму прогонки.

**Теорема** (_про достатні умови стійкості метода прогонки_): Нехай

$$
a_i, b_i \ne 0,
$$

та 

$$
\vert c_i \vert \ge \vert a_i \vert + \vert b_i \vert, \quad \forall i, \quad a_0 = b_N = 0,
$$

та хоча би одна нерівність строга. Тоді

$$
\vert \alpha_i \vert \le 1
$$

та

$$
z_i = c_i - a_i \alpha_i \ne 0, \quad i = \overline{1, N}.
$$

**Задача 8:** Довести теорему про стійкість методу прогонки

[Назад до лекцій](README.md)

[Назад на головну](../README.md)
