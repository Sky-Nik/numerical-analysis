{% include mathjax %}

<!-- MarkdownTOC -->

- [3. Методи розв'язання систем лінійних алгебраїчних рівнянь \(СЛАР\)](#3-методи-розвязання-систем-лінійних-алгебраїчних-рівнянь-слар)
	- [3.1. Метод Гаусса](#31-метод-гаусса)
	- [3.2. Метод квадратних коренів](#32-метод-квадратних-коренів)

<!-- /MarkdownTOC -->

<a id="3-методи-розвязання-систем-лінійних-алгебраїчних-рівнянь-слар"></a>
## 3. Методи розв'язання систем лінійних алгебраїчних рівнянь (СЛАР)

Методи розв'язування СЛАР поділяються на прямі та ітераційні. При умові точного виконання обчислень прямі методи за скінчену кількість операцій в результаті дають точний розв'язок. Використовуються вони для невеликих та середніх СЛАР $$n = 10^2 - 10^4$$. Ітераційні методи використовуються для великих СЛАР $$n > 10^5$$, як правило розріджених. В результаті отримуємо послідовність наближень, яка збігається до розв'язку.

<a id="31-метод-гаусса"></a>
### 3.1. Метод Гаусса

Література:

- Самарский, Гулин, 49&ndash;67: [djvu](../books/samarskyi-gulin-1989.djvu), [pdf](../books/samarskyi-gulin-1989-49-67.pdf);

- Березин, Жидков, том II, 10&ndash;23: [djvu](../books/berezin-zhidkov-ii-1962.djvu), [pdf](../books/berezin-zhidkov-ii-1962-10-23.pdf).

Розглянемо задачу розв'язання СЛАР

\begin{equation}
	\label{eq:3.1.1}
	A \vec x = \vec b,	
\end{equation}

причому $$A = (a_{ij})_{i, j = 1}^n$$, $$\det A \ne 0$$, $$\vec x = (x_i)_{i = 1}^n$$, $$\vec b = (b_j)_{j = 1}^n$$. Метод Крамера з обчисленням визначників для такої системи має складність $$Q = O(n! \cdot n)$$.

Запишемо СЛАР у вигляді

$$
\left\{
	\begin{aligned}
		& a_{1, 1} x_1 + a_{1, 2} x_2 + \ldots + a_{1, n} x_n = b_1 \equiv a_{1, n + 1}, \\
		& a_{2, 1} x_1 + a_{2, 2} x_2 + \ldots + a_{2, n} x_n = b_2 \equiv a_{2, n + 1}, \\
		& \ldots \\
		& a_{n, 1} x_1 + a_{n, 2} x_2 + \ldots + a_{n, n} x_n = b_n \equiv a_{n, n + 1}.
	\end{aligned}
\right.
$$

Якщо $$a_{1, 1} \ne 0$$, то ділимо перше рівняння на нього і виключаємо $$x_1$$ з інших рівнянь:

$$
\left\{
	\begin{aligned}
		x_1 + a_{1, 2}^{(1)} x_2 + \ldots + a_{1, n}^{(1)} x_n = a_{1, n + 1}^{(1)}, & \newline
		a_{2, 2}^{(1)} x_2 + \ldots + a_{2, n}^{(1)} x_n = a_{2, n + 1}^{(1)}, & \newline
		\ldots & \newline
		a_{n, 2} x_2^{(1)} + \ldots + a_{n, n}^{(1)} x_n = a_{n, n + 1}^{(1)} &.
	\end{aligned}
\right.
$$

Процес повторюємо для $$x_2, \ldots, x_n$$. В результаті отримуємо систему з трикутною матрицею

$$
\left\{ 
	\begin{array}{r}
		x_1 + a_{1, 2}^{(1)} x_2 + \ldots + a_{1, n}^{(1)} x_n = a_{1, n + 1}^{(1)},  \newline
		x_2 + \ldots + a_{2, n}^{(2)} x_n = a_{2, n + 1}^{(2)}, \newline
		\ldots \newline
		x_n = a_{n, n + 1}^{(n)}.
	\end{array}
\right.
$$

Тобто
\begin{equation}
	\label{eq:3.1.2}
	A^{(n)} \vec x = \vec a^{(n)}.
\end{equation}

Це прямий хід методу Гаусса. Формули прямого ходу

```python
for k in range(1, n):
  for j in range(k + 1, n + 2):
    a[k, j][k] = a[k, j][k - 1] / a[k, k][k - 1]
    for i in range(k + 1, n + 1):
      a[i, j][k] = a[i, j][k - 1] - \
        a[i, j][k - 1] * a[k, j][k]
```

Звідси

\begin{equation}
	\label{eq:3.1.3}
	x_n = a_{n, n + 1}^{(n)}, \quad x_i = a_{i, n + 1}^{(i)} - \Sum_{j = i + 1}^n a_{i, j}^{(n)} x_j,
\end{equation}

для $$i = \overline{n - 1, 1}$$. Це формули оберненого ходу.

Складність, тобто кількість операцій, яку необхідно виконати для реалізації методу: $$Q_{\text{пр.}} = 2/3 n^2 + O(n^2)$$ для прямого ходу, $$Q_{\text{об.}} = n^2 + O(n)$$ для оберненого ходу.

Умова $$a_{k, k}^{(k - 1)} \ne 0$$ не суттєва, оскільки знайдеться $$m$$, для якого $$\vert a_{m, k}^{(k - 1)} \vert = \Max_i \vert a_{i, k}^{(k - 1)} \vert \ne 0$$ (оскільки $$\det A \ne 0$$). Тоді міняємо місцями рядки номерів $$k$$ і $$m$$. Елемент $$a_{k, k}^{(k - 1)} \ne 0$$ називається ведучим.

Введемо матриці

$$
M_k = \begin{pmatrix} 
	1 & \cdots & 0 & \cdots & 0 \\ 
	\vdots & \ddots & \vdots & \ddots & \vdots \\ 
	0 & \cdots & m_{k,k} & \cdots & 0 \\ 
	\vdots & \ddots & \vdots & \ddots & \vdots \\ 
	0 & \cdots & m_{n,k} & \cdots & 1
\end{pmatrix}
$$

елементи якої обчислюється так: $$m_{k, k} = \frac{1}{a_{k, k}^{(k - 1)}}$$, $$m_{k, k} = - \frac{a_{i, k}^{(k - 1)}}{a_{k, k}^{(k - 1)}}$$.

Нехай на $$k$$-му кроці $$A_{k - 1} \vec x = \vec b_{k - 1}$$. Множимо цю СЛАР зліва на $$M_k$$: $$M_k A_{k - 1} \vec x = M_K \vec b_{k - 1}$$. Позначимо $$A_k = M_k A_{k - 1}$$; $$A_0 = A$$. Тоді прямий хід методу Гаусса можна записати у вигляді

$$
M_n M_{n - 1} \ldots M_1 A \vec x = M_n M_{n - 1} \ldots M_1 \vec b.
$$

Позначимо останню систему, яка співпадає з \eqref{eq:3.1.2}, так

\begin{equation}
	\label{eq:3.1.4}
	U \vec x = \vec c, \quad U = (u_{i, j})_{i, j = 1}^n,
\end{equation}

причому

$$
\begin{cases}
	u_{i, i} = 1, & \\
	u_{i, j} = 0, & i > j.
\end{cases}
$$

Таким чином $$U = M_n M_{n - 1} \ldots M_1 A$$. Введемо матриці

$$
L_k = M_k^{-1} = \begin{pmatrix} 
	1 & \cdots & 0 & \cdots & 0 \\ 
	\vdots & \ddots & \vdots & \ddots & \vdots \\ 
	0 & \cdots & a_{k,k}^{(k-1)} & \cdots & 0 \\ 
	\vdots & \ddots & \vdots & \ddots & \vdots \\ 
	0 & \cdots & a_{n,k}^{(k-1)} & \cdots & 1 
\end{pmatrix}
$$

Тоді

$$
A = L_1 \ldots L_n U = L U; \quad L = L_1 \ldots L_n,
$$

де $$L$$ &mdash; нижня трикутня матриця, $$U$$ &mdash; верхня трикутня матриця. Таким чином метод Гаусса можна трактувати, як розклад матриці $$A$$ в добуток двох трикутних матриць &mdash; $$LU$$-розклад.

Введемо матрицю перестановок на $$k$$-му кроці (це матриця, отримана з одиничної матриці перестановкою $$k$$-того і $$m$$-того рядка). Тоді при множені на неї матриці $$A_{k - 1}$$ робимо ведучим елементом максимальний за модулем.

$$
P_k = \begin{pmatrix} 
	1 & \cdots & 0 & \cdots & 0 & \cdots & 0 \\ 
	\vdots & \ddots & \vdots & \ddots & \vdots & \ddots & \vdots \\ 
	0 & \cdots & 0 & \cdots & 1 & \cdots & 0 \\ 
	\vdots & \ddots & \vdots & \ddots & \vdots & \ddots & \vdots \\ 
	0 & \cdots & 1 & \cdots & 0 & \cdots & 0 \\ 
	\vdots & \ddots & \vdots & \ddots & \vdots & \ddots & \vdots \\ 
	0 & \cdots & 0 & \cdots & 0 & \cdots & 1 \\ 
\end{pmatrix}
$$

За допомогою цих матриць перехід до трикутної системи \eqref{eq:3.1.4} тепер має вигляд:

$$
M_n M_{n - 1} P_{n - 1} \ldots M_1 P_1 A \vec x = M_n M_{n - 1} P_{n - 1} \ldots M_1 P_1 \vec b.
$$

**Твердження:** Знайдеться така матриця $$P$$ перестановок, що $$P A = L U$$ &mdash; розклад матриці на нижню трикутну з ненульовими діагональними елементами і верхню трикутну матрицю з одиницями на діагоналі.

Висновки про **переваги** трикутного розкладу:

- Розділення прямого і оберненого ходів дає змогу економно розв'язувати декілька систем з одноковою матрицею та різними правими частинами.

- Зберігання $$M$$, або $$L$$ та $$U$$ на місці $$А$$.

- Обчислюючи $$\ell$$ &mdash; кількість перестановок, можна встановити знак визначника.

<a id="32-метод-квадратних-коренів"></a>
### 3.2. Метод квадратних коренів

- Самарский, Гулин, 69&ndash;73: [djvu](../books/samarskyi-gulin-1989.djvu), [pdf](../books/samarskyi-gulin-1989-69-73.pdf);

- Березин, Жидков, том II, 23&ndash;25: [djvu](../books/berezin-zhidkov-ii-1962.djvu), [pdf](../books/berezin-zhidkov-ii-1962-23-25.pdf).

Цей метод призначений для розв'язання систем рівнянь із симетричною матрицею

\begin{equation}
	\label{eq:3.2.1}
	A \vec x = \vec b, \quad A^\intercal = A.
\end{equation}

Він оснований на розкладі матриці $$A$$ в добуток:

\begin{equation}
	\label{eq:3.2.2}
	A = S^\intercal D S,
\end{equation}

де $$S$$ &mdash; верхня трикутна матриця, $$S^\intercal$$ &mdash; нижня трикутна матриця, $$D$$ &mdash; діагональна матриця.

Виникає питання: як обчислити $$S$$, $$D$$ по матриці $$A$$? Маємо

$$
\begin{equation}
	\label{eq:3.2.3}
	(DS)_{i, j} = \begin{cases}
		d_{i, i} s_{i, j}, & i \le j, \\
		0, & i > j.
	\end{cases}
\end{equation}
$$

$$
\begin{align}
	(S^\intercal D S)_{i, j} &= \Sum_{l = 1}^n s_{i, l}^\intercal d_{l, l} s_{l, j} = \label{eq:3.2.4} \newline
	&= \Sum_{l = 1}^{i - 1} s_{l, i}^\intercal s_{l, j} d_{l, l} + s_{i, i} s_{i, j} d_{i, i} + \nonumber \newline
	&\quad + \underset{= 0}{\underbrace{s_{l, i}^\intercal \Sum_{l = i + 1}^n s_{l, i^\intercal s_{l, j} d_{l, l}} = \nonumber \newline
	= a_{i, j}. \nonumber 
\end{align}
$$

для $$i, j = \overline{1, n}$$.

Якщо $$i = j$$, то

$$
\vert s_{i, i}^2 \vert d_{i, i} = a_{i, i} - \Sum_{l = 1}^{i - 1} \vert s_{l, i}^2 \vert d_{l, l} \equiv p_i.
$$

Тому

[Назад до лекцій](README.md)

[Назад на головну](../README.md)
